{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sample data concists of scanned, hand written digits. The goal is to write a program that can correctly identify the digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"/tmp/data\", one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data concists of 55000 digits. Each digit is digitalized with values between 0 and 1, indigating the greyness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55000, 784)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.train.images.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grab a random image and view it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784,)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.train.images[2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = mnist.train.images[45000].reshape(28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x11ff4ee10>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nhB8I6n/cRjna850pFAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11ff17e48>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(sample, cmap=\"Greys\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "learning_rate = 0.001   # lower value gives better result but slower\n",
    "training_epochs = 20    # number of cycles\n",
    "batch_size = 100        # number of samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define parameters that are needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = 10         # number of digits that will be checked\n",
    "n_samples = mnist.train.num_examples\n",
    "n_input = 784          # what the input looks like\n",
    "n_hidden_1 = 256       # number of neurons in the hidden layers\n",
    "n_hidden_2 = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multilayer_perceptron(x, weights, biases):\n",
    "    '''\n",
    "    x: Placeholder for data input\n",
    "    weights: Dictionary of weights\n",
    "    biases: dictionary of bias values\n",
    "    '''\n",
    "    # first hidden layer rectifier activation \n",
    "    # x * w + b\n",
    "    layer_1 = tf.add(tf.matmul(x, weights['h1']), biases['b1'])\n",
    "    # Pass layer 1 to the RELU function. f(x) = max(0, x)\n",
    "    layer_1 = tf.nn.relu(layer_1)\n",
    "    \n",
    "    # second hidden layer\n",
    "    layer_2 = tf.add(tf.matmul(layer_1, weights['h2']), biases['b1'])\n",
    "    layer_2 = tf.nn.relu(layer_2)\n",
    "    \n",
    "    # finally the output layer\n",
    "    out_layer = tf.matmul(layer_2, weights['out'] + biases['out'])\n",
    "    return out_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = {\n",
    "    'h1': tf.Variable(tf.random_normal([n_input,n_hidden_1])),\n",
    "    'h2': tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2])),\n",
    "    'out': tf.Variable(tf.random_normal([n_hidden_2, n_classes]))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "biases = {\n",
    "    'b1': tf.Variable(tf.random_normal([n_hidden_1])),\n",
    "    'b2': tf.Variable(tf.random_normal([n_hidden_2])),\n",
    "    'out': tf.Variable(tf.random_normal([n_classes]))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Declare placeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, [None, n_input])\n",
    "y = tf.placeholder(tf.float32, [None, n_classes])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare model and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred =multilayer_perceptron(x, weights, biases)\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=pred))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Investigating xsamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = mnist.train.next_batch(1)\n",
    "Xsamp, ysamp = t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1219ef8d0>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x128776fd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(Xsamp.reshape(28, 28), cmap=\"Greys\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ysamp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ysamp has a 1 at postition 9, since the digit is a 9."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initializes weights and biases\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, cost=876.8503\n",
      "Epoch: 2, cost=36.5654\n",
      "Epoch: 3, cost=22.3659\n",
      "Epoch: 4, cost=15.7197\n",
      "Epoch: 5, cost=11.7144\n",
      "Epoch: 6, cost=9.1075\n",
      "Epoch: 7, cost=7.1420\n",
      "Epoch: 8, cost=5.6862\n",
      "Epoch: 9, cost=4.5923\n",
      "Epoch: 10, cost=3.7096\n",
      "Epoch: 11, cost=3.0551\n",
      "Epoch: 12, cost=2.4904\n",
      "Epoch: 13, cost=2.0281\n",
      "Epoch: 14, cost=1.6531\n",
      "Epoch: 15, cost=1.3869\n",
      "Epoch: 16, cost=1.1367\n",
      "Epoch: 17, cost=0.9263\n",
      "Epoch: 18, cost=0.7807\n",
      "Epoch: 19, cost=0.6713\n",
      "Epoch: 20, cost=0.5350\n",
      "Model completed 20 Epochs of training\n"
     ]
    }
   ],
   "source": [
    "# launch session\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(init)\n",
    "\n",
    "# Run 15 loops (training_epochs = 15)\n",
    "for epoch in range(training_epochs):\n",
    "    # Goal is to minimize cost\n",
    "    avg_cost = 0.0\n",
    "    \n",
    "    total_batch = int(n_samples/batch_size)\n",
    "    \n",
    "    # loop over all batches\n",
    "    for i in range(total_batch):\n",
    "        # Grab the next batch of training data and labels\n",
    "        batch_x,batch_y = mnist.train.next_batch(batch_size)\n",
    "        _, c = sess.run([optimizer, cost], feed_dict={x: batch_x, y: batch_y})\n",
    "        \n",
    "        # compute average cost\n",
    "        avg_cost += c/total_batch\n",
    "        \n",
    "    print(\"Epoch: {}, cost={:.4f}\".format(epoch+1, avg_cost))\n",
    "    \n",
    "print(\"Model completed {} Epochs of training\".format(training_epochs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9307"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_predictions = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
    "correct_predictions = tf.cast(correct_predictions, tf.float32)\n",
    "accuracy = tf.reduce_mean(correct_predictions)\n",
    "accuracy.eval({x: mnist.test.images, y:mnist.test.labels})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Cast_1:0\", shape=(?,), dtype=float32)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
